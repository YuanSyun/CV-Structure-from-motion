{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW4: Structure-from-motion\n",
    "\n",
    "Ref:\n",
    "\n",
    "- https://blog.csdn.net/haizimin/article/details/49836077\n",
    "- https://github.com/jesolem/PCV/blob/master/pcv_book/sfm.py\n",
    "- multiple view geometry in computer vision\n",
    "http://cvrs.whu.edu.cn/downloads/ebooks/Multiple%20View%20Geometry%20in%20Computer%20Vision%20(Second%20Edition).pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import random\n",
    "\n",
    "import hw3\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG_IMAGE_INDEX = 1\n",
    "RANSAC_INLINER_THRESHOLD = 0.000005\n",
    "RANSAC_SAMPLE_NUMBER = 2000\n",
    "\n",
    "if(DEBUG_IMAGE_INDEX==1):\n",
    "    image1 = cv2.imread('./data/Mesona1.JPG')\n",
    "    image2 = cv2.imread('./data/Mesona2.JPG')\n",
    "elif(DEBUG_IMAGE_INDEX == 2):\n",
    "    image1 = cv2.imread('./data/Statue1.bmp')\n",
    "    image2 = cv2.imread('./data/Statue2.bmp')\n",
    "image1 = cv2.cvtColor(image1, cv2.COLOR_BGR2RGB)\n",
    "image2 = cv2.cvtColor(image2, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intrinsic Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intrinsic Matrix 1\n",
      " [[ 1421.9     5.    509.2]\n",
      " [    0.   1421.9   380.2]\n",
      " [    0.      0.      1. ]]\n",
      "Intrinsic Matrix 2\n",
      " [[ 1421.9     5.    509.2]\n",
      " [    0.   1421.9   380.2]\n",
      " [    0.      0.      1. ]]\n"
     ]
    }
   ],
   "source": [
    "intrinsic_matrix1 = np.zeros((3,3))\n",
    "intrinsic_matrix1 = np.zeros((3,3))\n",
    "rotation_matrix1, rotation_matrix2 = None, None\n",
    "transform_matrix1, transform_matrix2 = None, None\n",
    "\n",
    "if(DEBUG_IMAGE_INDEX == 1):\n",
    "    intrinsic_matrix1 = np.array([[1.4219, 0.005, 0.5092],\n",
    "                                  [0, 1.4219, 0.3802],\n",
    "                                  [0, 0, 0.0010]])\n",
    "    intrinsic_matrix1 = intrinsic_matrix1 / intrinsic_matrix1[2,2]\n",
    "    intrinsic_matrix2 = intrinsic_matrix1\n",
    "else:\n",
    "    intrinsic_matrix1 = np.array([[5426.566895, 0.678017, 330.096680],\n",
    "                 [0.000000, 5423.133301, 648.950012],\n",
    "                 [0.000000, 0.000000, 1.000000]])\n",
    "    rotation_matrix1 = np.array([[0.140626, 0.989027, -0.045273],\n",
    "              [0.475766, -0.107607, -0.872965],\n",
    "              [-0.868258, 0.101223, -0.485678]])\n",
    "    transform_matrix1 = np.array([67.479439, -6.020049, 40.224911])\n",
    "\n",
    "    intrinsic_matrix2 = np.array([[5426.566895, 0.678017, 387.430023],\n",
    "                  [0.000000, 5423.133301, 620.616699],\n",
    "                  [0.000000, 0.000000, 1.000000]])\n",
    "    rotation_matrix2 = np.array([[0.336455, 0.940689, -0.043627],\n",
    "              [0.446741, -0.200225, -0.871970],\n",
    "              [-0.828988, 0.273889, -0.487611]])\n",
    "    transform_matrix2 = np.array([62.882744, -21.081516, 40.544052])\n",
    "    \n",
    "print(\"Intrinsic Matrix 1\\n\", intrinsic_matrix1)\n",
    "print(\"Intrinsic Matrix 2\\n\", intrinsic_matrix2)\n",
    "\n",
    "if(rotation_matrix1 is not None):\n",
    "    print('rotation_matrix1\\n', rotation_matrix1)\n",
    "    print('rotation_matrix2\\n', rotation_matrix2)\n",
    "    print('transform_matrix1\\n', transform_matrix1)\n",
    "    print('transform_matrix1\\n', transform_matrix2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'desc1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-0e5f700e5b37>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mimgpts1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimgpts2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m \u001b[0mimgpts1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimgpts2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_feature_points\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[0mmatched_feature_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhw3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow_matched_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimgpts1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimgpts2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdraw_line\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcircle_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatched_feature_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'off'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-0e5f700e5b37>\u001b[0m in \u001b[0;36mget_feature_points\u001b[1;34m(img1, img2)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mBF_MACTHER_DISTANCE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.25\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mmatches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhw3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbrute_force_matcher\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdesc1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdesc2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBF_MACTHER_DISTANCE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mmatched_pt_order\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhw3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_matched_points\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mimgpts1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimgpts2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhw3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_matched_points\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatched_pt_order\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeypt1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeypt2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'desc1' is not defined"
     ]
    }
   ],
   "source": [
    "def get_feature_points(img1, img2):\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "    (kp1, des1) = sift.detectAndCompute(image1, None)\n",
    "    (kp2, des2) = sift.detectAndCompute(image2, None)\n",
    "\n",
    "    BF_MACTHER_DISTANCE = 0.25\n",
    "    matches = hw3.brute_force_matcher(desc1, desc2, BF_MACTHER_DISTANCE)\n",
    "    matched_pt_order = hw3.sort_matched_points(matches)\n",
    "    imgpts1, imgpts2 = hw3.get_matched_points(matched_pt_order, keypt1, keypt2)\n",
    "    \n",
    "    # FLANN parameters\n",
    "#     FLANN_INDEX_KDTREE = 0\n",
    "#     index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "#     search_params = dict(checks=50)\n",
    "    \n",
    "#     flann = cv2.FlannBasedMatcher(index_params,search_params)\n",
    "#     matches = flann.knnMatch(des1,des2,k=2)\n",
    "    \n",
    "#     good = []\n",
    "#     pts1 = np.zeros((len(matches), 2), dtype=np.float64)\n",
    "#     pts2 = np.zeros((len(matches), 2), dtype=np.float64)\n",
    "    \n",
    "#     # ratio test as per Lowe's paper\n",
    "#     for i,(m,n) in enumerate(matches):\n",
    "#         if m.distance < 0.8*n.distance:\n",
    "#             good.append(m)\n",
    "#             pts1[i] = (kp1[m.queryIdx].pt)\n",
    "#             pts2[i] = (kp2[m.trainIdx].pt)\n",
    "            \n",
    "#     return pts1,pts2,good\n",
    "    \n",
    "    return imgpts1, imgpts2\n",
    "\n",
    "imgpts1, imgpts2, _ = get_feature_points(image1, image2)\n",
    "matched_feature_image = hw3.show_matched_image(image1, image2, imgpts1, imgpts2, draw_line=False, circle_size=10)\n",
    "plt.imshow(matched_feature_image), plt.axis('off'), plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fundamental and Essential Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normalization_matrix(img_shape):\n",
    "    '''\n",
    "        get the normalization matrix\n",
    "    '''\n",
    "    T = np.array([[2/img_shape[1], 0, -1],\n",
    "                   [0, 2/img_shape[0], -1],\n",
    "                   [0, 0, 1]])\n",
    "    return T\n",
    "\n",
    "def normalization(imgpts1, imgpts2, img1, img2):\n",
    "    '''\n",
    "        ref: lecture P.54\n",
    "    '''\n",
    "    # t1: image1 normalization matrix, t2: image2 normalization matrix\n",
    "    t1 = get_normalization_matrix(img1.shape)\n",
    "    t2 = get_normalization_matrix(img2.shape)\n",
    "    \n",
    "    # to homography coordinate\n",
    "    homopts1 = np.array([ [each[0], each[1], 1.0] for each in imgpts1])\n",
    "    homopts2 = np.array([ [each[0], each[1], 1.0] for each in imgpts2])\n",
    "    \n",
    "    num_of_point = len(imgpts1)\n",
    "    for i in range(num_of_point): \n",
    "        \n",
    "        # the Homogeneous coefficient should be one\n",
    "        p2h = np.matmul(t1, homopts1[i])\n",
    "        homopts1[i] = p2h/p2h[-1]\n",
    "        \n",
    "        p2h1 = np.matmul(t2, homopts2[i])\n",
    "        homopts2[i] = p2h1/p2h1[-1]\n",
    "    \n",
    "    normalpts1 = np.delete(homopts1, -1, axis=1)\n",
    "    normalpts2 = np.delete(homopts2, -1, axis=1)\n",
    "    \n",
    "    return normalpts1, normalpts2, t1, t2\n",
    "\n",
    "def sample_points(pointA, pointB, sample_number):\n",
    "    sample_point_index = random.sample(range(pointA.shape[0]), sample_number)\n",
    "    sample_pointsA = np.zeros((sample_number,2))\n",
    "    sample_pointsB = np.zeros((sample_number,2))\n",
    "    for i in range(sample_number):\n",
    "        index = sample_point_index[i]\n",
    "        sample_pointsA[i] = pointA[index]\n",
    "        sample_pointsB[i] = pointB[index]\n",
    "    return sample_pointsA, sample_pointsB\n",
    "\n",
    "def denormalize_fundamental_mat(normalmat1, normalmat2, normalize_fundamental):\n",
    "    '''\n",
    "        ref: Multiple View Geometry in Computer Vision - Algorithm 11.1\n",
    "    '''\n",
    "    transpose_normalmat2 = np.transpose(normalmat2)\n",
    "    F = np.matmul(np.matmul(transpose_normalmat2, normalize_fundamental), normalmat1)\n",
    "    F = F/F[-1,-1]\n",
    "    return F\n",
    "\n",
    "def get_fundamental(normalpts1, normalpts2):\n",
    "    '''\n",
    "        ref: Multiple View Geometry in Computer Vision - Chapter 11.1, lecture P.50\n",
    "    '''\n",
    "    \n",
    "    A = np.zeros((len(normalpts1), 9), dtype=np.float64)\n",
    "    for i in range(len(normalpts1)):\n",
    "        x, y = normalpts1[i][0], normalpts1[i][1]\n",
    "        xi, yi = normalpts2[i][0], normalpts2[i][1]\n",
    "        A[i] = np.array([xi*x, xi*y, xi, yi*x, yi*y, yi, x, y, 1])\n",
    "    \n",
    "    # resolve det(f) = 0\n",
    "    u, s, v = np.linalg.svd(A)\n",
    "    F = v[-1]\n",
    "    F = F.reshape(3, 3)\n",
    "    u, s, v = np.linalg.svd(F)\n",
    "    s = np.array([[s[0], 0 ,0],\n",
    "                 [0, s[1], 0],\n",
    "                 [0 , 0, 0]])\n",
    "    F = np.dot(np.dot(u, s), v)\n",
    "\n",
    "    return F\n",
    "\n",
    "def get_geometric_error(testpts1, testpts2, fundamentalmat, inliner_threshold):\n",
    "    '''\n",
    "        ref: Multiple View Geometry 11.4.3\n",
    "    '''\n",
    "    error = 0\n",
    "    inliner_number = 0\n",
    "    inlinerpt_indexs = np.zeros((len(testpts1),1))\n",
    "    for i in range(len(testpts1)):\n",
    "        \n",
    "        # transform test points to homography coordinate\n",
    "        x1 = np.array([testpts1[i][0], testpts1[i][1], 1])\n",
    "        x2 = np.array([testpts2[i][0], testpts2[i][1], 1])\n",
    "        \n",
    "        fx = np.dot(fundamentalmat, x1)\n",
    "        ftx = np.dot(fundamentalmat.T, x2)\n",
    "        \n",
    "        m = np.power(np.dot(np.dot(x2.T, fundamentalmat), x1), 2)\n",
    "        d = np.power(fx[0], 2) + np.power(fx[1], 2) + np.power(ftx[0], 2) + np.power(ftx[1], 2)\n",
    "        \n",
    "        distance = m/d\n",
    "        if(distance < inliner_threshold):\n",
    "            error += distance\n",
    "            inlinerpt_indexs[inliner_number] = i\n",
    "            inliner_number += 1\n",
    "            \n",
    "    return error, inliner_number, inlinerpt_indexs[:inliner_number, :]\n",
    "\n",
    "def get_inliner_points(x1, x2, inliner_indexs):\n",
    "    inlinerpts1 = np.zeros((len(inliner_indexs), 2))\n",
    "    inlinerpts2 = np.zeros((len(inliner_indexs), 2))\n",
    "    \n",
    "    for i in range(inliner_indexs.shape[0]):\n",
    "        inlinerpts1[i] = x1[i]\n",
    "        inlinerpts2[i] = x2[i]\n",
    "    \n",
    "    return inlinerpts1, inlinerpts2\n",
    "\n",
    "def get_essential_mat(K1, K2, F):\n",
    "    '''\n",
    "        ref: Multiple View Geometry 9.12\n",
    "    '''\n",
    "    if(K1[-1,-1] != 1):\n",
    "        K1 = K1 / K1[-1,-1]\n",
    "    if(K2[-1,-1] != 1):\n",
    "        K2 = K2 / K2[-1,-1]\n",
    "        \n",
    "    E = np.dot( K2.T , np.dot(F,K1))\n",
    "    \n",
    "    return E\n",
    "\n",
    "def find_fundamental_by_RANSAC(imgpts1, imgpts2, img1, img2, inliner_threshold, ransac_iteration = 2000):\n",
    "    '''\n",
    "        ref: Multiple View Geometry 11.6\n",
    "    '''\n",
    "    \n",
    "    best_fundamental = np.zeros((3,3))\n",
    "    best_inlinernum = -1\n",
    "    \n",
    "    print(\"Key Point Number\\n\", len(imgpts1))\n",
    "    ransac_sample_number = 8\n",
    "    \n",
    "    # normalization the key points\n",
    "    normalpts1, normalpts2, nomalmat1, normalmat2 = normalization(imgpts1, imgpts2, img1, img2)\n",
    "    best_error = 0\n",
    "    best_inlinerpt_index = []\n",
    "    \n",
    "    for i in range(ransac_iteration):\n",
    "        \n",
    "        sampts1, sampts2 = sample_points(normalpts1, normalpts2, ransac_sample_number)\n",
    "        unnormalized_f = get_fundamental(sampts1, sampts2)\n",
    "        error, inlinernum, inlinerpt_indexs = get_geometric_error(normalpts1, normalpts2, unnormalized_f, inliner_threshold)\n",
    "        \n",
    "        if(inlinernum > best_inlinernum):\n",
    "            best_error = error\n",
    "            best_fundamental = unnormalized_f\n",
    "            best_inlinernum = inlinernum\n",
    "            best_inlinerpt_index = inlinerpt_indexs\n",
    "            \n",
    "    # homographs coefficient and denormalize the fundamental matrix\n",
    "    best_fundamental = denormalize_fundamental_mat(nomalmat1, normalmat2, best_fundamental)\n",
    "    best_essential = get_essential_mat(intrinsic_matrix1, intrinsic_matrix2, best_fundamental)\n",
    "    best_inlinerpts1, best_inlinerpts2 = get_inliner_points(imgpts1, imgpts2, best_inlinerpt_index)\n",
    "    \n",
    "    print(\"RANSC Error\\n\", best_error)\n",
    "    print(\"Inliner Number\\n\", best_inlinernum)\n",
    "    \n",
    "    return best_fundamental, best_essential, best_inlinerpts1, best_inlinerpts2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the fundamnetal matrix\n",
    "fundamentalmat, essentialmat, inlinerpts1, inlinerpts2 = find_fundamental_by_RANSAC(imgpts1, imgpts2, image1, image2, RANSAC_INLINER_THRESHOLD, RANSAC_SAMPLE_NUMBER)\n",
    "\n",
    "print('keypts1.shape\\n', imgpts1.shape)\n",
    "print(\"F\\n\", fundamentalmat)\n",
    "print(\"E\\n\", essentialmat)\n",
    "print('inlinerpts1.sahpe\\n', inlinerpts1.shape)\n",
    "print('inlinerpts2.sahpe\\n', inlinerpts2.shape)\n",
    "\n",
    "# by opencv\n",
    "fundamentalmat_opencv, _= cv2.findFundamentalMat(imgpts1, imgpts2, method =cv2.FM_8POINT + cv2.FM_RANSAC)\n",
    "essentialmat_opencv = get_essential_mat(intrinsic_matrix1, intrinsic_matrix2, fundamentalmat_opencv)\n",
    "\n",
    "print(\"F by opencv\\n\", fundamentalmat_opencv)\n",
    "print(\"E by opencv\\n\", essentialmat_opencv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw Epipolar Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def compute_correspond_epilines(keypts, which_image, fundamental):\n",
    "    '''\n",
    "        ref: https://github.com/opencv/opencv/blob/f5801ee7dac4114ac2995a5fd3866ac7775752f7/modules/calib3d/src/fundam.cpp#L836\n",
    "        l = Fx'\n",
    "        l' = F^Tx\n",
    "    '''\n",
    "    lines = np.zeros((len(keypts), 3))\n",
    "    \n",
    "    if (which_image == 2):\n",
    "        fundamental = np.transpose(fundamental)\n",
    "    \n",
    "    for i, p in enumerate(keypts):\n",
    "        hp = np.array([p[0], p[1], 1])\n",
    "        l = np.matmul(fundamental, np.transpose(hp))\n",
    "        \n",
    "        a, b, c = l[0], l[1], l[2]\n",
    "        check = a*a + b*b\n",
    "        if check != 0:\n",
    "            check = np.sqrt(check)\n",
    "        else:\n",
    "            check = 1\n",
    "        lines[i] = np.array([a/check, b/check ,c/check])\n",
    "        \n",
    "    return lines\n",
    "\n",
    "def draw_epilines(img1, img2, lines, pts1, pts2, colors):\n",
    "    '''\n",
    "        ref: https://docs.opencv.org/3.4.4/da/de9/tutorial_py_epipolar_geometry.html\n",
    "        x0, y0 = (0, -b/c)\n",
    "        x1, y1 = (w, -(aw+c)/b)\n",
    "    '''\n",
    "    imgA = np.copy(img1)\n",
    "    imgB = np.copy(img2)\n",
    "    h, w, _ = img1.shape\n",
    "    \n",
    "    i=0\n",
    "    for r,pt1, pt2 in zip(lines, pts1, pts2):\n",
    "        x0, y0 = (0, int(-r[2]/r[1]))\n",
    "        x1, y1 = (w, int(-(r[0]*w+r[2])/r[1]))\n",
    "        imgA = cv2.line(imgA, (x0, y0), (x1, y1), colors[i], 5)\n",
    "        imgA = cv2.circle(imgA, (int(pt1[0]), int(pt1[1])), 15, (255, 0, 0), -1)\n",
    "        imgB = cv2.circle(imgB, (int(pt2[0]), int(pt2[1])), 15, (255, 0, 0), -1)\n",
    "        i += 1\n",
    "    return imgA, imgB\n",
    "\n",
    "# prepare line color\n",
    "colors = np.zeros((len(inlinerpts1), 3))\n",
    "for i in range(len(inlinerpts1)):\n",
    "    colors[i] = tuple(np.random.randint(0, 255, 3).tolist())\n",
    "\n",
    "# show image epilines\n",
    "lines1 = compute_correspond_epilines(inlinerpts2, 2, fundamentalmat)\n",
    "img3, _ = draw_epilines(image1, image2, lines1, inlinerpts1, inlinerpts2, colors)\n",
    "lines2 = compute_correspond_epilines(inlinerpts1, 1, fundamentalmat)\n",
    "img4, _ = draw_epilines(image2, image1, lines2, inlinerpts1, inlinerpts2, colors)\n",
    "\n",
    "# by opencv\n",
    "lines3 = cv2.computeCorrespondEpilines(inlinerpts2, 2, fundamentalmat_opencv)\n",
    "lines3 = lines3.reshape(-1,3)\n",
    "img5, _ = draw_epilines(image1, image2, lines3, inlinerpts1, inlinerpts2, colors)\n",
    "lines4 = cv2.computeCorrespondEpilines(inlinerpts1, 1, fundamentalmat_opencv)\n",
    "lines4 = lines4.reshape(-1,3)\n",
    "img6, _ = draw_epilines(image2, image1, lines4, inlinerpts1, inlinerpts2, colors)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(321), plt.imshow(image1)\n",
    "plt.subplot(322), plt.imshow(image2)\n",
    "plt.subplot(323), plt.imshow(img3)\n",
    "plt.subplot(324), plt.imshow(img4)\n",
    "plt.subplot(325),plt.imshow(img5)\n",
    "plt.subplot(326),plt.imshow(img6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Triangulation\n",
    "project matirx = K[R|t] = 3x4\n",
    "\n",
    "camera matrix = intrinsic matrix = k = 3x3\n",
    "\n",
    "external rotation matrix = R = 3x3\n",
    "\n",
    "translation matrix = t = 1x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_external(r, t):\n",
    "    ex = np.array([[r[0,0], r[0,1], r[0,2], t[0]],\n",
    "                   [r[1,0], r[1,1], r[1,2], t[1]],\n",
    "                   [r[2,0], r[2,1], r[2,2], t[2]],])\n",
    "    return ex\n",
    "def get_camera_matrix(e, k1, k2):\n",
    "    '''\n",
    "        ref: Multiple View Geometry 9.13\n",
    "    '''\n",
    "    # check the intrinc matrix Homogeneous coefficient\n",
    "    if(k1[-1,-1] != 1.):\n",
    "        k1 = k1/k1[-1,-1]\n",
    "    if(k2[-1,-1] != 1.):\n",
    "        k2 = k2/k2[-1,-1]\n",
    "    \n",
    "    # camera 1 project matrix\n",
    "    I = np.array([[1, 0, 0],\n",
    "                  [0, 1, 0],\n",
    "                  [0, 0, 1]])\n",
    "    p1 = np.matmul(k1, combine_external(I, [0, 0, 0]))\n",
    "\n",
    "    # skew-symmetric\n",
    "    W = np.array([[0, -1, 0], \n",
    "                  [1, 0, 0], \n",
    "                  [0, 0, 1]])\n",
    "    \n",
    "    U, S, Vt = np.linalg.svd(e)\n",
    "    R1 = np.matmul(np.matmul(U, W), Vt)\n",
    "    R2 = np.matmul(np.matmul(U, W.T), Vt)\n",
    "    t= U[:,-1].reshape(3,1)\n",
    "\n",
    "    # Thre have four camera direction (ref: Multiple View Geometry 9.14)\n",
    "    p2_matrixs = np.zeros((4, 3, 4))\n",
    "    p2_matrixs[0] = np.matmul(k2, combine_external(R1, t))\n",
    "    p2_matrixs[1] = np.matmul(k2, combine_external(R2, t))\n",
    "    p2_matrixs[2] = np.matmul(k2, combine_external(R1, -t))\n",
    "    p2_matrixs[3] = np.matmul(k2, combine_external(R2, -t))\n",
    "    \n",
    "    return p1, p2_matrixs\n",
    "\n",
    "def get_external(e):\n",
    "    '''\n",
    "        get external parameter\n",
    "        ref: homework lecture page 3\n",
    "    '''\n",
    "    w = np.array([[0.0, -1.0, 0.0],[1.0, 0.0, 0.0],[0.0, 0.0, 1.0]])\n",
    "    z = np.array([[0.0, 1.0, 0.0],[-1.0, 0.0, 0.0],[0.0, 0.0, 0.0]])\n",
    "    \n",
    "    U, S, V = np.linalg.svd(e)\n",
    "    m = (S[0] + S[1])/2\n",
    "    S[0] = m\n",
    "    S[1] = m\n",
    "    S[2] = 0\n",
    "\n",
    "    T1 = U[:3]\n",
    "    T2 = -U[:3]\n",
    "    R1 = np.matmul(np.matmul(U, w.T), V)\n",
    "    R2 = np.matmul(np.matmul(U, w), V)\n",
    "    \n",
    "    print('U\\n', U)\n",
    "    print('T1\\n', T1)\n",
    "\n",
    "    if(np.linalg.det(R1)==-1.0):\n",
    "        R1 = -1*R1\n",
    "        R2 = -1*R2\n",
    "        \n",
    "    return t, R1, R2\n",
    "\n",
    "def linear_LS_Triangulation(x1, p1, x2, p2):\n",
    "    '''\n",
    "        ref: 1995 Triangulation, ch5.1 Linear Triangulation\n",
    "        https://perception.inrialpes.fr/Publications/1997/HS97/HartleySturm-cviu97.pdf\n",
    "    '''\n",
    "    A = np.array([x1[0]*p1[2,:]-p1[0,:], \n",
    "                  x1[1]*p1[2,:]-p1[1,:],\n",
    "                  x2[0]*p2[2,:]-p2[0,:],\n",
    "                  x2[1]*p2[2,:]-p2[1,:]])\n",
    "    \n",
    "    U, S, V = np.linalg.svd(A)\n",
    "    X = V[-1]/V[-1,3]\n",
    "    return X\n",
    "\n",
    "def in_front_of_camera(T, R, pts,is_opencv=False):\n",
    "    num_of_points = 0\n",
    "    camera_center = -np.dot(np.transpose(R),T)\n",
    "    vide_direciton = np.transpose(R)[2,:]\n",
    "    for i in range(pts.shape[0]):\n",
    "        if is_opencv:\n",
    "            hp = pts[:,i]\n",
    "            hp = hp/hp[-1]\n",
    "            X_location = hp[:3] - camera_center\n",
    "        else: \n",
    "            X_location = pts[i] - camera_center\n",
    "        if np.dot(X_location,vide_direciton) > 0 :\n",
    "            num_of_points = num_of_points + 1\n",
    "    return num_of_points\n",
    "\n",
    "def get_triangulatepts(e, x1, x2, p1, p2):\n",
    "    \n",
    "    T, R1, R2 = get_external(e)\n",
    "    \n",
    "    front_count = 0\n",
    "    project_points = np.zeros((x1.shape[0], 3))\n",
    "    \n",
    "    # linear triangulate\n",
    "    for i in range(x1.shape[0]):\n",
    "        x = linear_LS_Triangulation(x1[i], p1, x2[i], p2)\n",
    "        project_points[i] = x[0:3]\n",
    "        \n",
    "    front_count1 = in_front_of_camera(T, R1, project_points)\n",
    "    \n",
    "    return project_points, front_count\n",
    "\n",
    "def triangulate_points(e, x1, x2, k1, k2, r1=None, r2=None, t1=None, t2=None):\n",
    "    \n",
    "    p1 = None\n",
    "    p2 = None\n",
    "    \n",
    "    if(r1 is not None):\n",
    "        print('this has external matrix')\n",
    "        t1 = -np.matmul(r1, t1)\n",
    "        t2 = -np.matmul(r2, t2)\n",
    "        p1 = np.matmul(k1, combine_external(r1, t1))\n",
    "        p2 = np.matmul(k2, combine_external(r2, t2))\n",
    "        \n",
    "        triangulation_points, front_count = get_triangulatepts(e, x1, x2, p1, p2)\n",
    "        \n",
    "    else:\n",
    "        p1, p2_matrixs = get_camera_matrix(e, k1, k2)\n",
    "\n",
    "        max_front_count = -1\n",
    "        correct_p2_index = -1\n",
    "        triangulation_points = np.zeros((x1.shape[0], 3))\n",
    "\n",
    "        for p2_index in range(p2_matrixs.shape[0]):\n",
    "            project_points, front_count = get_triangulatepts(e, x1, x2, p1, p2_matrixs[p2_index])       \n",
    "            if(front_count > max_front_count):\n",
    "                max_front_count = front_count\n",
    "                triangulation_points = np.copy(project_points)\n",
    "                p2 = p2_matrixs[p2_index]\n",
    "\n",
    "    return triangulation_points, p1, p2\n",
    "\n",
    "def show_cloud_points(pts, cv_pts=None):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    fig.suptitle('3D reconstructed', fontsize=16)\n",
    "    ax.set_xlabel('x axis')\n",
    "    ax.set_ylabel('y axis')\n",
    "    ax.set_zlabel('z axis')\n",
    "    for i, p in enumerate(pts):\n",
    "        xs = p[0]\n",
    "        ys = p[1]\n",
    "        zs = p[2]\n",
    "        ax.scatter(xs, ys, zs, color='#054E9F', s=3)\n",
    "        \n",
    "    if(cv_pts is not None):\n",
    "        for i in range(cv_pts.shape[1]):\n",
    "            hp = cv_pts[:,i] \n",
    "            x = hp[0]\n",
    "            y = hp[1]\n",
    "            z = hp[2]\n",
    "            ax.scatter(x, y, z, color='#000000', s=3)\n",
    "    plt.show()\n",
    "\n",
    "def get_cv_projectpts(pts):\n",
    "    projectpts = np.transpose(pts)\n",
    "    return projectpts\n",
    "\n",
    "# our triangulate method\n",
    "project_pts, p1, p2 = triangulate_points(essentialmat,\n",
    "                                         inlinerpts1, inlinerpts2,\n",
    "                                         intrinsic_matrix1, intrinsic_matrix2,\n",
    "                                         rotation_matrix1, rotation_matrix2,\n",
    "                                         transform_matrix1, transform_matrix2)\n",
    "\n",
    "# opencv triagulate method, need transform the format of inliner points\n",
    "cv_inlinerpts1 = get_cv_projectpts(inlinerpts1)\n",
    "cv_inlinerpts2 = get_cv_projectpts(inlinerpts2)\n",
    "cloudpts1_cv = cv2.triangulatePoints(p1, p2, cv_inlinerpts1, cv_inlinerpts2)\n",
    "\n",
    "#show_cloud_points(project_pts, cloudpts1_cv)\n",
    "show_cloud_points(project_pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import answer\n",
    "\n",
    "a_x1, a_x2, _ = answer.sift_detector(image1, image2)\n",
    "\n",
    "a_x1 = np.float64(a_x1)\n",
    "a_x2 = np.float64(a_x2)\n",
    "\n",
    "# normalization the key points\n",
    "normalpts1, normalpts2, nomalmat1, normalmat2 = answer.get_normalize(a_x1, a_x2, image1.shape, image2.shape)\n",
    "answer_f, mask = answer.get_fundamental(normalpts1, normalpts2, nomalmat1, normalmat2)\n",
    "print('anser f\\n', answer_f)\n",
    "\n",
    "anser_e = get_essential_mat(intrinsic_matrix1, intrinsic_matrix2, answer_f)\n",
    "\n",
    "a_inlinerpts1 = a_x1[mask.ravel()==1]\n",
    "a_inlinerpts2 = a_x2[mask.ravel()==1]\n",
    "X = answer.cal_P(anser_e, a_inlinerpts1, a_inlinerpts2, intrinsic_matrix1, intrinsic_matrix2)\n",
    "\n",
    "show_cloud_points(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Data For MatLab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t,R1,R2 = get_external(essentialmat)\n",
    "camera_matrix = np.matmul( intrinsic_matrix1, combine_external(R1.T, t) )\n",
    "file_name = ''\n",
    "\n",
    "if(DEBUG_IMAGE_INDEX == 1):\n",
    "    file_name = 'Mesona1'\n",
    "elif (DEBUG_IMAGE_INDEX == 2):\n",
    "    file_name = 'Statue1'\n",
    "else:\n",
    "    file_name = 'our'\n",
    "    \n",
    "np.savetxt(\"./data/two_d_points_\"+file_name+\".csv\", inlinerpts1, delimiter=\",\")\n",
    "np.savetxt(\"./data/three_d_points_\"+file_name+\".csv\", project_pts, delimiter=\",\")\n",
    "np.savetxt(\"./data/camera_matrix_\"+file_name+\".csv\", camera_matrix, delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
